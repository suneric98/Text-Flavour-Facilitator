{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import emoji\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK = \"<unk>\"\n",
    "empty = \"<empty>\"\n",
    "wordEmbSize = 64\n",
    "data = pd.read_csv(\"data3.csv\")\n",
    "\n",
    "split = np.random.rand(len(data)) < 0.8\n",
    "trainData = data[split]\n",
    "testData = data[~split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "+ Cleaning by using nltk word tokenizer and lemmatizer\n",
    "+ Adds spaces to emojis to separate them to different words using emoji library's re\n",
    "+ Add a start and end token\n",
    "+ Build vocab for words\n",
    "+ Build vocab for emojis\n",
    "+ Makes labels as 0 or 1 for each word. If label is 1, means that word is followed by an emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RE_EMOJI = emoji.get_emoji_regexp()\n",
    "tokenizer = nltk.word_tokenize\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "# tokens normalized\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "#converting text to words\n",
    "def preprocessing(data, train=True):\n",
    "    newData = {\"words\":[], \"labels\":[]}\n",
    "    for text in data[\"texts\"]:\n",
    "        #converting to words\n",
    "        emoji_split = RE_EMOJI.split(text)\n",
    "        emoji_split = [x.strip() for x in emoji_split if x]\n",
    "        text = \" \".join(emoji_split)\n",
    "        textWords = LemNormalize(text)\n",
    "        textWords.insert(0,\"<s>\")\n",
    "        textWords.append(\"</s>\")\n",
    "        newData[\"words\"].append(textWords)\n",
    "        \n",
    "        #getting labels\n",
    "        labels = []\n",
    "        if train:\n",
    "            for i in range(1, len(textWords)):\n",
    "                word = textWords[i]\n",
    "                if RE_EMOJI.match(word):\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels = [0 * len(textWords)]\n",
    "        newData[\"labels\"].append(labels)\n",
    "    return pd.DataFrame(newData)\n",
    "\n",
    "def make_vocabs(data):\n",
    "    vocab = set()\n",
    "    vocab.add(UNK)\n",
    "    emojiVocab = set()\n",
    "#     emojiVocab.add(empty)\n",
    "    for text in data[\"words\"]:\n",
    "        for word in text:\n",
    "            vocab.add(word)\n",
    "            if RE_EMOJI.match(word):\n",
    "                emojiVocab.add(word)\n",
    "    return vocab, emojiVocab\n",
    "\n",
    "def remove_unk(data, vocab):\n",
    "    updatedData = []\n",
    "    for text in data[\"words\"]:\n",
    "        updatedWords = [word if word in vocab else UNK for word in text]\n",
    "        updatedData.append(updatedWords)\n",
    "    data[\"words\"] = updatedData\n",
    "    return data\n",
    "\n",
    "train = preprocessing(trainData, True)\n",
    "vocab, emojiVocab = make_vocabs(train)\n",
    "vocabIdx = {word : i for i, word in enumerate(vocab)}\n",
    "eVocabIdx = {emoji : i for i, emoji in enumerate(emojiVocab)}\n",
    "\n",
    "test = preprocessing(testData, True)\n",
    "test = remove_unk(test, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "+ Using gensim's Word2Vec\n",
    "+ Builds model with word embedding size specified earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=19720, size=64, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericsun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "def getEmbModel(data, vocab):\n",
    "    docs = [[UNK]]\n",
    "    docs.extend(data[\"words\"])\n",
    "    model = Word2Vec(docs, min_count = 1, size = wordEmbSize)\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "# Takes: dataset, word2vec model, and vocabulary from training\n",
    "# returns: list of tuples. First value is a torch of word embeddings for that sentence,\n",
    "# second value is the labels for each word\n",
    "def getEmb(data, model, vocab):\n",
    "    vecData = []\n",
    "    for text,y in zip(data[\"words\"],data[\"labels\"]):\n",
    "        wordEmb = []\n",
    "        for word in text:\n",
    "            if word in vocab:\n",
    "                wordEmb.append(model[word])\n",
    "            else:\n",
    "                wordEmb.append(model[UNK])\n",
    "        wordEmb = torch.FloatTensor(wordEmb)\n",
    "        vecData.append((wordEmb, y))\n",
    "    return vecData\n",
    "\n",
    "model = getEmbModel(train, vocab)\n",
    "trainEmb = getEmb(train, model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'wyd', 'want', 'ya', 'as', 'whoop', 'peep', 'the', 'champion', 'ship', 'kid', 'i', 'll', 'beat', 'your', 'as', 'no', 'regrits', 'i', 'll', 'slap', 'your', 'dimb', 'as', 'back', 'to', 'the', 'foreign', 'land', 'u', 'came', 'from', 'bitch', 'i', '‚Äô', 'm', 'the', 'champion', 'and', 'you', '‚Äô', 're', 'just', 'a', 'faggot', 'silly', 'as', 'bitch', 'you', 'don', '‚Äô', 't', 'won', '‚Äô', 't', 'none', 'u', 'ain', '‚Äô', 't', 'want', 'none', 'ah', 'shit', 'ah', 'shit', 'u', 'gone', 'get', 'the', 'smoke', 'u', 'gone', 'get', 'the', 'smoke', 'better', 'run', 'big', 'homie', 'üôè', 'ima', 'be', 'wildin', 'üí™üèº', 'üí™üèº', '</s>']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0]\n",
      "tensor([[ 0.7273,  0.1699,  0.9712,  ..., -0.2124, -0.4577, -0.6436],\n",
      "        [ 0.0443, -0.0031,  0.0582,  ..., -0.0107, -0.0257, -0.0257],\n",
      "        [ 1.1425,  1.1755,  0.2185,  ...,  0.0246,  0.0571, -0.5433],\n",
      "        ...,\n",
      "        [ 0.1292, -0.0161,  0.1577,  ...,  0.0156, -0.0363, -0.0544],\n",
      "        [ 0.1292, -0.0161,  0.1577,  ...,  0.0156, -0.0363, -0.0544],\n",
      "        [ 1.2456, -1.0004,  1.7114,  ..., -0.8050, -0.9158, -0.8631]])\n",
      "['<s>', 'my', 'mom', 'told', 'me', 'that', 'making', 'silly', 'face', 'will', 'deform', 'my', 'face', 'permanently', 'so', 'i', 'decided', 'to', 'grab', 'the', 'tip', 'of', 'my', 'wiener', 'and', 'stretch', 'it', 'out', 'so', 'it', 'stay', 'that', 'way', 'and', 'now', 'i', 'have', 'a', 'monster', 'schlong', 'that', 'i', 'use', 'to', 'pound', 'down', 'coeds', 'single', 'mother', 'and', 'indecisive', 'nun', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'ü§ô', 'üôÄ', 'üôÄ', 'üôÄ', 'üôÄ', 'üôÄ', 'üôÄ', 'üòù', 'üòù', 'üòù', '</s>']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "tensor([[ 0.7273,  0.1699,  0.9712,  ..., -0.2124, -0.4577, -0.6436],\n",
      "        [ 1.2790,  0.6184,  0.9539,  ...,  0.1060,  0.2872, -0.4923],\n",
      "        [ 0.8962,  0.0695,  1.0728,  ..., -0.1335, -0.5141, -0.7245],\n",
      "        ...,\n",
      "        [ 0.8358, -0.2230,  0.7057,  ..., -0.1851, -0.2907, -0.3447],\n",
      "        [ 0.8358, -0.2230,  0.7057,  ..., -0.1851, -0.2907, -0.3447],\n",
      "        [ 1.2456, -1.0004,  1.7114,  ..., -0.8050, -0.9158, -0.8631]])\n",
      "['<s>', 'mmmm', 'üòã', 'yummy', 'üéÇ', 'nuzzles', 'uwu', 'i', 'would', 'like', 'that', 'ü§î', 'ü§î', 'uwo', 'cake', 'san', 'owo', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéÇ', 'üéâ', 'üéâ', 'üóø', 'üëÅ', 'üëÑ', 'üëÅ', 'üçÜ', 'üí¶', 'üí¶', 'üí¶', '</s>']\n",
      "[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "tensor([[ 0.7273,  0.1699,  0.9712,  ..., -0.2124, -0.4577, -0.6436],\n",
      "        [ 0.0903, -0.0557,  0.1027,  ..., -0.0242, -0.0404, -0.0243],\n",
      "        [ 1.2573, -0.4091,  0.8898,  ..., -0.3616, -0.2561, -0.2963],\n",
      "        ...,\n",
      "        [ 2.5742, -1.5234,  0.2404,  ..., -0.4789, -0.1054,  0.3467],\n",
      "        [ 2.5742, -1.5234,  0.2404,  ..., -0.4789, -0.1054,  0.3467],\n",
      "        [ 1.2456, -1.0004,  1.7114,  ..., -0.8050, -0.9158, -0.8631]])\n",
      "['<s>', 'üèñ', 'Ô∏è', '</s>']\n",
      "[1, 0, 0, 0]\n",
      "tensor([[ 7.2726e-01,  1.6986e-01,  9.7121e-01,  5.8852e-01,  2.7817e-01,\n",
      "         -2.2763e-01,  8.0213e-01,  5.3056e-01, -7.3688e-01, -4.5865e-01,\n",
      "          9.3313e-01, -6.3995e-01, -5.7220e-01, -4.2415e-01, -2.2641e+00,\n",
      "          2.3747e-01, -7.4974e-01,  4.1084e-01, -8.4809e-01, -8.3708e-01,\n",
      "          6.4842e-01,  3.8501e-01,  9.9012e-01,  1.2551e+00,  1.4059e-01,\n",
      "          1.2008e-01,  8.3197e-01,  4.2933e-01, -2.1520e-02,  4.3401e-01,\n",
      "         -6.8466e-01, -3.5092e-01,  1.0899e+00,  3.6074e-01, -2.1296e-01,\n",
      "          3.5588e-01,  7.8533e-01,  4.7931e-01, -1.1690e+00, -3.5963e-02,\n",
      "         -1.7988e-01,  8.8599e-01, -6.6987e-01, -3.6189e-01, -6.1912e-01,\n",
      "          2.5736e-01, -8.2217e-02, -4.2039e-01,  1.4788e-01,  2.3726e-01,\n",
      "          5.5950e-01, -8.4930e-02, -4.7443e-01,  4.7667e-01,  2.1528e-01,\n",
      "         -5.7130e-01, -1.2360e+00, -2.8946e-01,  3.7736e-01,  3.0347e-01,\n",
      "          1.2015e+00, -2.1242e-01, -4.5774e-01, -6.4362e-01],\n",
      "        [ 1.1451e-01,  2.7811e-02,  1.2876e-01,  6.0310e-02,  2.5549e-03,\n",
      "          1.0572e-02,  7.2684e-02,  6.8380e-02, -5.0676e-02, -8.4193e-02,\n",
      "          8.7068e-02, -6.6984e-02, -1.7258e-01, -7.7277e-02, -2.6144e-01,\n",
      "          5.2432e-02, -1.0224e-01,  6.8006e-03, -1.6994e-01, -1.5574e-01,\n",
      "          7.8554e-02,  2.9380e-02,  1.4740e-01,  1.2935e-01,  6.5990e-02,\n",
      "          2.0315e-02,  1.3562e-01,  2.2785e-02,  6.0340e-02,  1.7560e-02,\n",
      "         -9.7694e-02, -7.6742e-02,  1.6274e-01,  4.0209e-02, -7.5462e-03,\n",
      "          2.1008e-03,  4.6673e-02,  7.1334e-02, -1.8401e-01, -9.6933e-02,\n",
      "          1.6468e-02,  1.1461e-01, -6.8171e-02, -2.7870e-02, -2.9372e-02,\n",
      "          8.5482e-02, -5.4172e-02,  1.6328e-02,  8.0889e-02, -1.3758e-03,\n",
      "          1.4766e-01,  1.2986e-02, -1.3303e-01,  5.3422e-02, -3.8647e-02,\n",
      "         -9.2575e-02, -1.5680e-01,  7.4950e-03,  9.4187e-02,  3.9002e-02,\n",
      "          1.5962e-01, -2.5821e-02, -2.5514e-02, -6.0594e-02],\n",
      "        [ 1.3879e+00,  1.1722e+00,  1.9823e+00, -9.0712e-02, -2.5079e-02,\n",
      "         -6.3628e-01,  1.8290e+00,  8.7728e-01, -1.5054e+00, -1.1151e+00,\n",
      "          7.1583e-01, -4.2598e-02, -2.4625e+00, -1.5962e+00, -1.9488e+00,\n",
      "          1.7066e+00, -2.3149e+00, -9.8071e-01, -1.8560e+00, -2.3762e+00,\n",
      "          8.2514e-01,  2.1575e-01,  9.6111e-01,  1.9118e+00,  2.1239e+00,\n",
      "         -1.7474e+00,  8.1934e-01,  1.5746e+00,  7.4971e-02,  7.8872e-01,\n",
      "         -2.5332e+00, -1.0186e-01,  1.9817e+00, -2.8003e-01,  6.5026e-01,\n",
      "         -7.7839e-01,  2.2944e-01,  1.2429e+00, -1.4552e+00, -6.5039e-01,\n",
      "          8.9878e-01, -1.2821e-01,  1.3584e+00,  4.4000e-01, -6.2404e-01,\n",
      "          3.4016e-01, -3.4858e-01, -1.2504e-01, -3.6135e-01, -4.6246e-01,\n",
      "          2.8651e+00,  5.4993e-01, -2.1824e+00,  1.5862e+00, -7.7815e-01,\n",
      "         -3.0155e+00, -2.1631e+00,  2.2600e-01,  2.6297e+00,  4.5401e-01,\n",
      "          1.4875e+00, -9.9085e-01,  1.4374e+00,  3.5217e-01],\n",
      "        [ 1.2456e+00, -1.0004e+00,  1.7114e+00, -2.2952e-01,  3.6275e-01,\n",
      "         -2.0836e-01,  7.7651e-01,  1.3954e+00,  1.4116e-02, -1.1155e+00,\n",
      "          9.9989e-01, -7.4059e-01, -5.9150e-01, -5.2857e-01, -2.2251e+00,\n",
      "          6.4183e-01, -1.2679e+00,  1.5664e-01, -4.1107e-01, -1.9078e+00,\n",
      "          4.7396e-01,  1.8290e-01,  1.5861e+00,  1.7362e+00,  6.0337e-01,\n",
      "          6.8868e-01,  1.5024e+00, -2.4204e-01,  7.8437e-01,  4.0843e-01,\n",
      "         -1.8019e-01, -9.7452e-01,  1.7699e+00,  8.3374e-01,  6.1919e-02,\n",
      "          5.6143e-02,  2.8583e-01,  7.8587e-01, -1.3823e+00,  1.1856e-01,\n",
      "          2.3726e-01,  8.8314e-01, -1.0341e+00, -5.6608e-01, -1.2908e-01,\n",
      "          1.3028e+00, -2.5143e-01, -3.7123e-01, -3.0773e-03, -2.9983e-01,\n",
      "          1.3009e+00,  2.5422e-01, -5.1866e-01, -2.5710e-01,  3.0743e-01,\n",
      "         -1.2240e+00, -1.6279e+00, -6.9121e-01,  1.0497e+00,  5.1282e-01,\n",
      "          5.2040e-01, -8.0499e-01, -9.1582e-01, -8.6314e-01]])\n",
      "['<s>', 'üé∫', 'if', 'üé∫', 'you', 'üé∫', 'get', 'üé∫', 'an', 'üé∫', 'email', 'üé∫', 'titled', 'üé∫', 'big', 'üé∫', 'tiddy', 'üé∫', 'skeleton', 'üé∫', 'pic', 'üé∫', 'dont', 'üé∫', 'open', 'üé∫', 'it', 'üé∫', 'it', 'üé∫', 'a', 'üé∫', 'virus', 'üé∫', 'and', 'üé∫', 'put', 'üé∫', 'trumpet', 'üé∫', 'between', 'üé∫', 'all', 'üé∫', 'your', 'üé∫', 'post', 'üé∫', '</s>']\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
      "tensor([[ 0.7273,  0.1699,  0.9712,  ..., -0.2124, -0.4577, -0.6436],\n",
      "        [ 0.5102,  0.0613,  0.5757,  ..., -0.0467, -0.2104, -0.2461],\n",
      "        [ 1.7161,  1.6499,  0.0825,  ..., -0.4355,  0.0191, -0.6309],\n",
      "        ...,\n",
      "        [ 0.4512,  0.4419,  0.4152,  ..., -0.0419, -0.0074, -0.3162],\n",
      "        [ 0.5102,  0.0613,  0.5757,  ..., -0.0467, -0.2104, -0.2461],\n",
      "        [ 1.2456, -1.0004,  1.7114,  ..., -0.8050, -0.9158, -0.8631]])\n"
     ]
    }
   ],
   "source": [
    "sample = train.sample(5)\n",
    "for index,row in sample.iterrows():\n",
    "    print(row[\"words\"])\n",
    "    print(row[\"labels\"])\n",
    "    print(trainEmb[index][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building supervised models to predict next emoji\n",
    "\n",
    "+ RNN based architecture where we look at the hidden layer for every word\n",
    "  + Using hidden layer, predict if is an emoji and what emoji it is\n",
    "+ Asked TA from NLP class, they said this is similar to a language modelling problem where we only predict the set of emoji vocabulary\n",
    "  + Could also view as sequence labelling where tag is next emoji or no emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "jupyter = True\n",
    "if jupyter:\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward NN\n",
    "\n",
    "+ https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "+ Built using previous couple of words\n",
    "+ Feature is word embeddings using pytorch nn.Embedding. Use vocabulary and map words to index and emojis to index. Entire vocabulary is fed as input to the NN but output of NN is either emoji or no emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, context_size, hidden):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, hidden)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        self.loss = nn.NLLLoss()\n",
    "        self.linear2 = nn.Linear(hidden, output_size)\n",
    "\n",
    "    def compute_loss(self, predicted_vector, label):\n",
    "        return self.loss(predicted_vector, label)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = self.activation(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = self.softmax(out)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFfeatures(data, numContext = 2):\n",
    "    grams = []\n",
    "    numEmpty = 0\n",
    "    total = 0\n",
    "    for text in data[\"words\"]:\n",
    "        curr = []\n",
    "        for i in range(len(text) - numContext):\n",
    "            predictWord = text[i+numContext]\n",
    "            if not RE_EMOJI.match(predictWord):\n",
    "                predictWord = 0\n",
    "                numEmpty += 1\n",
    "            else:\n",
    "                predictWord = 1\n",
    "            total += 1\n",
    "            context = [word for word in text[i:i+numContext]]\n",
    "            curr.append((context, predictWord))\n",
    "        grams.append(curr)\n",
    "    print(\"% empty:{}\".format(numEmpty / total))\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% empty:0.7183500017066594\n",
      "% empty:0.7298338285462749\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 4\n",
    "train_feats = FFfeatures(train, numContext=CONTEXT_SIZE)\n",
    "test_feats = FFfeatures(test, numContext=CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started for epoch:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11405fab1fdc4cf49de53bec0195bf01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericsun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed for epoch:1\n",
      "Time for train:392.81811571121216\n",
      "Accuracy:0.6136874267198807\n",
      "Guessed not emoji:130887 Guessed emoji:42250\n",
      "Validation started for epoch:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8689f6507049d396cbe7e772d5b580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation completed for epoch:1\n",
      "Time for validation:9.102935075759888\n",
      "Accuracy:0.27813709912047085\n",
      "Guessed not emoji:903 Guessed emoji:43780 %Emoji:0.9797909719580153\n",
      "Training started for epoch:2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf907ba87b049f6a1fc7151849d3926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed for epoch:2\n",
      "Time for train:397.34837198257446\n",
      "Accuracy:0.681239981086598\n",
      "Guessed not emoji:156974 Guessed emoji:16448\n",
      "Validation started for epoch:2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43db8f864f594bc1bed6da911598e7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation completed for epoch:2\n",
      "Time for validation:9.351760864257812\n",
      "Accuracy:0.7276592872570194\n",
      "Guessed not emoji:44448 Guessed emoji:0 %Emoji:0.0\n",
      "Training started for epoch:3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc043ae6b6414293bcb7cd5784caa238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed for epoch:3\n",
      "Time for train:672.4186429977417\n",
      "Accuracy:0.7171286466026587\n",
      "Guessed not emoji:173312 Guessed emoji:0\n",
      "Validation started for epoch:3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79553ebfcfe74666b753410a936e4c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation completed for epoch:3\n",
      "Time for validation:9.07215166091919\n",
      "Accuracy:0.7309490259231922\n",
      "Guessed not emoji:44709 Guessed emoji:0 %Emoji:0.0\n",
      "Training started for epoch:4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea205955150411a9f24c71d1027d61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed for epoch:4\n",
      "Time for train:395.56516695022583\n",
      "Accuracy:0.7185738719193728\n",
      "Guessed not emoji:174234 Guessed emoji:0\n",
      "Validation started for epoch:4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9b0090c17d414cac2ec095a949159a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation completed for epoch:4\n",
      "Time for validation:9.60697317123413\n",
      "Accuracy:0.729536887452881\n",
      "Guessed not emoji:44568 Guessed emoji:0 %Emoji:0.0\n",
      "Training started for epoch:5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f6ffd0f6c240e6a0fa39c6b806f8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-10a6b8deff24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training completed for epoch:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# FFNN with context to predict if emoji or not\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "model = NGramLanguageModeler(len(vocab), 2, EMBEDDING_DIM, CONTEXT_SIZE, 128)\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01, momentum=0.9)\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Training started for epoch:{}\".format(epoch + 1))\n",
    "    random.shuffle(train_feats)\n",
    "    start_time = time.time()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    guess0 = 0\n",
    "    guess1 = 0\n",
    "    minibatch_size = 16\n",
    "    N = len(train_feats)\n",
    "    for minibatch_idx in tqdm(range(N // minibatch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = None\n",
    "        for idx in range(minibatch_size):\n",
    "            text = train_feats[minibatch_idx * minibatch_size + idx]\n",
    "            for context, target in text:\n",
    "                context_idx = torch.tensor([vocabIdx[w] for w in context], dtype=torch.long)\n",
    "                log_probs = model(context_idx)\n",
    "                idx_loss = model.compute_loss(log_probs, torch.tensor([target]))\n",
    "                \n",
    "                if loss is None:\n",
    "                    loss = idx_loss\n",
    "                else:\n",
    "                    loss += idx_loss\n",
    "                predicted_label = torch.argmax(log_probs)\n",
    "                if predicted_label == 0:\n",
    "                    guess0 += 1\n",
    "                else:\n",
    "                    guess1 += 1\n",
    "                correct += int(predicted_label == target)\n",
    "                total += 1\n",
    "        loss = loss / minibatch_size\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Training completed for epoch:{}\".format(epoch + 1))\n",
    "    print(\"Time for train:{}\".format(time.time() - start_time))\n",
    "    print(\"Accuracy:{}\".format(correct / total))\n",
    "    print(\"Guessed not emoji:{} Guessed emoji:{}\".format(guess0, guess1))\n",
    "    \n",
    "    #validation\n",
    "    model.eval()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Validation started for epoch:{}\".format(epoch + 1))\n",
    "    random.shuffle(test_feats)\n",
    "    start_time = time.time()\n",
    "    correct = guess0 = guess1 = total = 0\n",
    "    minibatch_size = 16\n",
    "    N = len(test_feats)\n",
    "    for minibatch_idx in tqdm(range(N // minibatch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        for idx in range(minibatch_size):\n",
    "            text = test_feats[minibatch_idx * minibatch_size + idx]\n",
    "            for context, target in text:\n",
    "                context_idx = torch.tensor([vocabIdx[w] for w in context], dtype=torch.long)\n",
    "                log_probs = model(context_idx)\n",
    "\n",
    "                predicted_label = torch.argmax(log_probs)\n",
    "                if predicted_label == 0:\n",
    "                    guess0 += 1\n",
    "                else:\n",
    "                    guess1 += 1\n",
    "                correct += int(predicted_label == target)\n",
    "                total += 1\n",
    "    print(\"Validation completed for epoch:{}\".format(epoch + 1))\n",
    "    print(\"Time for validation:{}\".format(time.time() - start_time))\n",
    "    print(\"Accuracy:{}\".format(correct / total))\n",
    "    print(\"Guessed not emoji:{} Guessed emoji:{} %Emoji:{}\".format(guess0, guess1, guess1/(guess1+guess0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN/LSTM \n",
    "\n",
    "+ https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html#sphx-glr-beginner-nlp-sequence-models-tutorial-py\n",
    "+ 2 models\n",
    "  + one to determine whether a word is an emoji (treated as a seq labelling task)\n",
    "  + one to determine which emoji it is (also treated as seq labelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for predicting if Emoji or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, loss_weights, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        self.loss = nn.NLLLoss(weight=loss_weights)\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "    def compute_loss(self, predicted_vector, label):\n",
    "        return self.loss(predicted_vector, label)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = self.softmax(tag_space)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineEmojiFeats(data):\n",
    "    feats = []\n",
    "    for text,label in zip(data[\"words\"], data[\"labels\"]):\n",
    "        feats.append((text, label))\n",
    "    return feats\n",
    "\n",
    "train_feats = determineEmojiFeats(train)\n",
    "test_feats = determineEmojiFeats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started for epoch:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22fca4071bd4c9cb47bf9903ec677c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericsun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-c425f638797a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtext_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocabIdx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0midx_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-0bf3d03c7319>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtag_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, torch.tensor([0.5,1]), len(vocab), 2)\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01, momentum=0.9)\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Training started for epoch:{}\".format(epoch + 1))\n",
    "    random.shuffle(train_feats)\n",
    "    start_time = time.time()\n",
    "    correct = guess0 = guess1 = total = 0\n",
    "    minibatch_size = 16\n",
    "    N = len(train_feats)\n",
    "    for minibatch_idx in tqdm(range(N // minibatch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = None\n",
    "        for idx in range(minibatch_size):\n",
    "            text, label = train_feats[minibatch_idx * minibatch_size + idx]\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "            text_idx = torch.tensor([vocabIdx[w] for w in text], dtype = torch.long)\n",
    "            log_probs = model(text_idx)\n",
    "            idx_loss = model.compute_loss(log_probs, label)\n",
    "            if loss is None:\n",
    "                loss = idx_loss\n",
    "            else:\n",
    "                loss += idx_loss\n",
    "            for i in range(len(label)):\n",
    "                corr_label = label[i]\n",
    "                pred_label = torch.argmax(log_probs[i])\n",
    "                if pred_label == 0:\n",
    "                    guess0 += 1\n",
    "                else:\n",
    "                    guess1 += 1\n",
    "                correct += int(pred_label == corr_label)\n",
    "                total += 1\n",
    "        loss = loss / minibatch_size\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Training completed for epoch:{}\".format(epoch + 1))\n",
    "    print(\"Time for train:{}\".format(time.time() - start_time))\n",
    "    print(\"Accuracy:{}\".format(correct / total))\n",
    "    print(\"Guessed not emoji:{} Guessed emoji:{} %Emoji:{}\".format(guess0, guess1, guess1/(guess1+guess0)))\n",
    "    \n",
    "    #validation\n",
    "    model.eval()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Validation started for epoch:{}\".format(epoch + 1))\n",
    "    random.shuffle(test_feats)\n",
    "    start_time = time.time()\n",
    "    correct = guess0 = guess1 = total = 0\n",
    "    minibatch_size = 16\n",
    "    N = len(test_feats)\n",
    "    for minibatch_idx in tqdm(range(N // minibatch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        for idx in range(minibatch_size):\n",
    "            text, label = test_feats[minibatch_idx * minibatch_size + idx]\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "            text_idx = torch.tensor([vocabIdx[w] for w in text], dtype = torch.long)\n",
    "            log_probs = model(text_idx)\n",
    "            for i in range(len(label)):\n",
    "                corr_label = label[i]\n",
    "                pred_label = torch.argmax(log_probs[i])\n",
    "                if pred_label == 0:\n",
    "                    guess0 += 1\n",
    "                else:\n",
    "                    guess1 += 1\n",
    "                correct += int(pred_label == corr_label)\n",
    "                total += 1\n",
    "    print(\"Validation completed for epoch:{}\".format(epoch + 1))\n",
    "    print(\"Time for validation:{}\".format(time.time() - start_time))\n",
    "    print(\"Accuracy:{}\".format(correct / total))\n",
    "    print(\"Guessed not emoji:{} Guessed emoji:{} %Emoji:{}\".format(guess0, guess1, guess1/(guess1+guess0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for predicting emoji\n",
    "\n",
    "+ Still WIP\n",
    "+ Problems: possible outcomes is too high and our data is too sparse to guess emojis correctly\n",
    "+ Probably either need more data or narrow down data vocabulary significantly\n",
    "+ Simple hacky solution: build a mapping of certain words to certain emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        self.loss = nn.NLLLoss()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to output\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def compute_loss(self, predicted_vector, label):\n",
    "        return self.loss(predicted_vector, label)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        _, hidden = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        hidden = hidden.contiguous().view(-1, self.hidden_dim)\n",
    "        output = self.softmax(self.hidden2tag(hidden))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emojiTypeFeats(data):\n",
    "    feats = []\n",
    "    for text in data[\"words\"]:\n",
    "        curr = []\n",
    "        for wordIdx in range(len(text)):\n",
    "            word = text[wordIdx]\n",
    "            if RE_EMOJI.match(word):\n",
    "                curr.append((text[:wordIdx], eVocabIdx[word]))\n",
    "        feats.append(curr)\n",
    "    return feats\n",
    "\n",
    "train_feats = emojiTypeFeats(train)\n",
    "test_feats = emojiTypeFeats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started for epoch:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20f6ba79235415e8c3b5a069f7dfaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericsun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed for epoch:1\n",
      "Time for train:147.91556906700134\n",
      "Accuracy:0.052651767508529665\n",
      "Validation started for epoch:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9069d1871d42f8bed2256a9465ee02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation completed for epoch:1\n",
      "Time for validation:3.2849442958831787\n",
      "Accuracy:0.0037294878170064643\n",
      "Guessed not emoji:0 Guessed emoji:12066 %Emoji:1.0\n",
      "Training started for epoch:2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad262df3f4f74efa9001bd100b0373bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed for epoch:2\n",
      "Time for train:152.59969925880432\n",
      "Accuracy:0.0007692930601668151\n",
      "Validation started for epoch:2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5f02daa2a642708e1aaf9e995a36ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation completed for epoch:2\n",
      "Time for validation:3.8778717517852783\n",
      "Accuracy:0.0036277735594364294\n",
      "Guessed not emoji:11853 Guessed emoji:0 %Emoji:0.0\n",
      "Training started for epoch:3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c2c2a2ebff4365a66245506f8605b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed for epoch:3\n",
      "Time for train:145.50066494941711\n",
      "Accuracy:0.0003434620979473089\n",
      "Validation started for epoch:3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27fe8afb1a96447aba9130d949e148ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation completed for epoch:3\n",
      "Time for validation:3.6287479400634766\n",
      "Accuracy:0.00352834988102076\n",
      "Guessed not emoji:12187 Guessed emoji:0 %Emoji:0.0\n",
      "Training started for epoch:4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d44614e1df457d91462909ac5f4ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed for epoch:4\n",
      "Time for train:144.32569098472595\n",
      "Accuracy:0.0003451706564333719\n",
      "Validation started for epoch:4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19aa94f5d26d4fbebde5968f2797bc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation completed for epoch:4\n",
      "Time for validation:3.388035774230957\n",
      "Accuracy:0.0035824377239023577\n",
      "Guessed not emoji:12003 Guessed emoji:0 %Emoji:0.0\n",
      "Training started for epoch:5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050806fe471d4bcdb3a53b6eeb907ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-0504d46b78c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training completed for epoch:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "model = LSTMPredictor(EMBEDDING_DIM, HIDDEN_DIM, len(vocab), len(emojiVocab))\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01, momentum=0.9)\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Training started for epoch:{}\".format(epoch + 1))\n",
    "    random.shuffle(train_feats)\n",
    "    start_time = time.time()\n",
    "    correct = guess0 = guess1 = total = 0\n",
    "    minibatch_size = 16\n",
    "    N = len(train_feats)\n",
    "    for minibatch_idx in tqdm(range(N // minibatch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = None\n",
    "        for idx in range(minibatch_size):\n",
    "            text = train_feats[minibatch_idx * minibatch_size + idx]\n",
    "            for context, label in text:\n",
    "                label = torch.tensor(label, dtype=torch.long)\n",
    "                text_idx = torch.tensor([vocabIdx[w] for w in text], dtype = torch.long)\n",
    "                log_probs = model(text_idx)\n",
    "                idx_loss = model.compute_loss(log_probs, label)\n",
    "                if loss is None:\n",
    "                    loss = idx_loss\n",
    "                else:\n",
    "                    loss += idx_loss\n",
    "                for i in range(len(label)):\n",
    "                    corr_label = label[i]\n",
    "                    pred_label = torch.argmax(log_probs[i])\n",
    "                    if pred_label == 0:\n",
    "                        guess0 += 1\n",
    "                    else:\n",
    "                        guess1 += 1\n",
    "                    correct += int(pred_label == corr_label)\n",
    "                    total += 1\n",
    "        loss = loss / minibatch_size\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Training completed for epoch:{}\".format(epoch + 1))\n",
    "    print(\"Time for train:{}\".format(time.time() - start_time))\n",
    "    print(\"Accuracy:{}\".format(correct / total))\n",
    "    print(\"Guessed not emoji:{} Guessed emoji:{} %Emoji:{}\".format(guess0, guess1, guess1/(guess1+guess0)))\n",
    "    \n",
    "    #validation\n",
    "    model.eval()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Validation started for epoch:{}\".format(epoch + 1))\n",
    "    random.shuffle(test_feats)\n",
    "    start_time = time.time()\n",
    "    correct = guess0 = guess1 = total = 0\n",
    "    minibatch_size = 16\n",
    "    N = len(test_feats)\n",
    "    for minibatch_idx in tqdm(range(N // minibatch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        for idx in range(minibatch_size):\n",
    "            text = test_feats[minibatch_idx * minibatch_size + idx]\n",
    "            for context, label in text:\n",
    "                label = torch.tensor([label], dtype=torch.long)\n",
    "                text_idx = torch.tensor([vocabIdx[w] for w in text], dtype = torch.long)\n",
    "                log_probs = model(text_idx)\n",
    "                for i in range(len(label)):\n",
    "                    corr_label = label[i]\n",
    "                    pred_label = torch.argmax(log_probs[i])\n",
    "                    if pred_label == 0:\n",
    "                        guess0 += 1\n",
    "                    else:\n",
    "                        guess1 += 1\n",
    "                    correct += int(pred_label == corr_label)\n",
    "                    total += 1\n",
    "    print(\"Validation completed for epoch:{}\".format(epoch + 1))\n",
    "    print(\"Time for validation:{}\".format(time.time() - start_time))\n",
    "    print(\"Accuracy:{}\".format(correct / total))\n",
    "    print(\"Guessed not emoji:{} Guessed emoji:{} %Emoji:{}\".format(guess0, guess1, guess1/(guess1+guess0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
